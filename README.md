# llm-context-stretch
A Python module inspired by Recurrent Memory Transformer research that implements a chunking and search mechanism for larger-than-normal prompts.

# Credits
This rather dubious implementation was inspired by the following research:

- Scaling Transformer to 1M tokens and beyond with RMT
- Aydar Bulatov, Yuri Kuratov, Mikhail S. Burtsev
-	[arXiv:2304.11062](https://arxiv.org/abs/2304.11062)
